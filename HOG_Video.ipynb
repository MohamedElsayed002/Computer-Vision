{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "from  imutils.object_detection import non_max_suppression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'vtest.AVI'\n",
    "file_size = (1920,1080) # Assumes 1920x1080 mp4\n",
    "\n",
    "# We want to save the output to a video file\n",
    "\n",
    "output_filename = 'output_street_hog.mp4'\n",
    "output_frames_per_second = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Create a HOGDescriptor\n",
    "\n",
    "    hog = cv2.HOGDescriptor()\n",
    "\n",
    "    # Initialize the people Detector \n",
    "\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "    # Load a video \n",
    "\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    # Create a VideoWriter object so we can save the video output \n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "    result = cv2.VideoWriter(output_filename,\n",
    "                             fourcc,\n",
    "                             output_frames_per_second,\n",
    "                             file_size)\n",
    "    \n",
    "    # Process the video \n",
    "\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Capture one frame at a time \n",
    "\n",
    "        sucess , frame = cap.read()\n",
    "\n",
    "        # Do we have a video frame? If true, proceed.\n",
    "\n",
    "        if sucess:\n",
    "\n",
    "            # Store the original frame \n",
    "\n",
    "            orig_frame = frame.copy()\n",
    "\n",
    "            (bounding_boxes , weights) = hog.detectMultiScale(frame,\n",
    "                                                              winStride=(4,4),\n",
    "                                                              padding=(8,8),\n",
    "                                                              scale=0.01)\n",
    "            \n",
    "            # Draw bounding boxes on the frame \n",
    "\n",
    "            for (x,y,w,h) in bounding_boxes:\n",
    "\n",
    "                cv2.rectangle(orig_frame,\n",
    "                              (x,y),\n",
    "                              (x+w, y+h),\n",
    "                              (0,0,255),\n",
    "                              2)\n",
    "                \n",
    "                # Get rid of overlapping bounding boxes \n",
    "                # you can tweak the overlapThresh value for better results \n",
    "\n",
    "                bounding_boxes = np.array([[x,y,x+w,y+h] for (\n",
    "                    x , y , w , h) in bounding_boxes])\n",
    "                \n",
    "                selection = non_max_suppression(bounding_boxes)\n",
    "\n",
    "                # draw the final bounding boxes\n",
    "\n",
    "                for (x1,y1,x2,y2) in selection:\n",
    "\n",
    "                    cv2.rectangle(frame,\n",
    "                                  (x1,y1),\n",
    "                                  (x2,y2),\n",
    "                                  (0,255,0),\n",
    "                                  4)\n",
    "                    \n",
    "                # Write the frame to the output video file \n",
    "\n",
    "                result.write(frame)\n",
    "\n",
    "                # Display the frame \n",
    "\n",
    "                cv2.imshow('Frame', frame)\n",
    "\n",
    "                # Display frame for X milliseconds and check if q key is pressed\n",
    "\n",
    "                if cv2.waitKey(1) == ord('q'):\n",
    "                    break \n",
    "\n",
    "            else:\n",
    "                break \n",
    "\n",
    "            cap.release()\n",
    "\n",
    "            result.release()\n",
    "\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # Import the OpenCV library to enable computer vision\n",
    "import numpy as np # Import the NumPy scientific computing library\n",
    "from imutils.object_detection import non_max_suppression # Handle overlapping\n",
    " \n",
    "# Make sure the video file is in the same directory as your code\n",
    "filename = 'vtest.AVI'\n",
    "file_size = (1920,1080) # Assumes 1920x1080 mp4\n",
    "scale_ratio = 1 # Option to scale to fraction of original size. \n",
    " \n",
    "# We want to save the output to a video file\n",
    "output_filename = 'pedestrians_on_street.mp4'\n",
    "output_frames_per_second = 20.0\n",
    " \n",
    "def main():\n",
    " \n",
    "  # Create a HOGDescriptor object\n",
    "  hog = cv2.HOGDescriptor()\n",
    "     \n",
    "  # Initialize the People Detector\n",
    "  hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "     \n",
    "  # Load a video\n",
    "  cap = cv2.VideoCapture(filename)\n",
    " \n",
    "  # Create a VideoWriter object so we can save the video output\n",
    "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "  result = cv2.VideoWriter(output_filename,  \n",
    "                           fourcc, \n",
    "                           output_frames_per_second, \n",
    "                           file_size) \n",
    "     \n",
    "  # Process the video\n",
    "  while cap.isOpened():\n",
    "         \n",
    "    # Capture one frame at a time\n",
    "    success, frame = cap.read() \n",
    "         \n",
    "    # Do we have a video frame? If true, proceed.\n",
    "    if success:\n",
    "         \n",
    "        # Resize the frame\n",
    "      width = int(frame.shape[1] * scale_ratio)\n",
    "      height = int(frame.shape[0] * scale_ratio)\n",
    "      frame = cv2.resize(frame, (width, height))\n",
    "             \n",
    "      # Store the original frame\n",
    "      orig_frame = frame.copy()\n",
    "             \n",
    "      # Detect people\n",
    "      # image: a single frame from the video\n",
    "      # winStride: step size in x and y direction of the sliding window\n",
    "      # padding: no. of pixels in x and y direction for padding of \n",
    "      # sliding window\n",
    "      # scale: Detection window size increase coefficient   \n",
    "      # bounding_boxes: Location of detected people\n",
    "      # weights: Weight scores of detected people\n",
    "      # Tweak these parameters for better results\n",
    "      (bounding_boxes, weights) = hog.detectMultiScale(frame, \n",
    "                                                       winStride=(16, 16),\n",
    "                                                       padding=(4, 4), \n",
    "                                                       scale=1.05)\n",
    " \n",
    "      # Draw bounding boxes on the frame\n",
    "      for (x, y, w, h) in bounding_boxes: \n",
    "            cv2.rectangle(orig_frame, \n",
    "            (x, y),  \n",
    "            (x + w, y + h),  \n",
    "            (0, 0, 255), \n",
    "             2)\n",
    "                         \n",
    "      # Get rid of overlapping bounding boxes\n",
    "      # You can tweak the overlapThresh value for better results\n",
    "      bounding_boxes = np.array([[x, y, x + w, y + h] for (\n",
    "                                x, y, w, h) in bounding_boxes])\n",
    "             \n",
    "      selection = non_max_suppression(bounding_boxes, \n",
    "                                      probs=None, \n",
    "                                      overlapThresh=0.45)\n",
    "         \n",
    "      # draw the final bounding boxes\n",
    "      for (x1, y1, x2, y2) in selection:\n",
    "        cv2.rectangle(frame, \n",
    "                     (x1, y1), \n",
    "                     (x2, y2), \n",
    "                     (0, 255, 0), \n",
    "                      4)\n",
    "         \n",
    "      # Write the frame to the output video file\n",
    "      result.write(frame)\n",
    "             \n",
    "      # Display the frame \n",
    "      cv2.imshow(\"Frame\", frame)    \n",
    " \n",
    "      # Display frame for X milliseconds and check if q key is pressed\n",
    "      # q == quit\n",
    "      if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "         \n",
    "    # No more video frames left\n",
    "    else:\n",
    "      break\n",
    "             \n",
    "  # Stop when the video is finished\n",
    "  cap.release()\n",
    "     \n",
    "  # Release the video recording\n",
    "  result.release()\n",
    "     \n",
    "  # Close all windows\n",
    "  cv2.destroyAllWindows() \n",
    " \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
